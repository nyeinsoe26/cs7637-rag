{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cwd=/home/nyein/georgia_tech_masters/cs7637/rag\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "# change cwd\n",
    "project_root = \"/home/nyein/georgia_tech_masters/cs7637/cs7637-rag\"\n",
    "os.chdir(project_root)\n",
    "cwd = os.getcwd()\n",
    "print(f\"cwd={cwd}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "dotenv_path = Path('.env')\n",
    "load_dotenv(dotenv_path=dotenv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using personal key\n"
     ]
    }
   ],
   "source": [
    "def load_openai_keys(use_personal=False):\n",
    "    if use_personal:\n",
    "        print(f\"Using personal key\")\n",
    "        return os.getenv(\"OPENAI_API_KEY\")\n",
    "    print(\"Using chanwah's key\")\n",
    "    return os.getenv(\"chanwah_openai_api_key\")\n",
    "openai_key = load_openai_keys(True)\n",
    "os.environ[\"OPENAI_API_KEY\"] = openai_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "embedding_manager = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-small\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_postgres import PGVector\n",
    "from langchain_postgres.vectorstores import PGVector\n",
    "\n",
    "connection = \"postgresql+psycopg://langchain:langchain@localhost:6024/langchain\"  # Uses psycopg3!\n",
    "collection_name = \"my_docs\"\n",
    "\n",
    "\n",
    "vector_store = PGVector(\n",
    "    embeddings=embedding_manager,\n",
    "    collection_name=collection_name,\n",
    "    connection=connection,\n",
    "    use_jsonb=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relevant_lecture_slide(\n",
    "    query: str,\n",
    "    num_distinct_lect: int = 3,\n",
    "):\n",
    "    res = vector_store.similarity_search(\n",
    "        query,\n",
    "        k=10,\n",
    "    )\n",
    "    distinct_lect = []\n",
    "    distinct_lect_ids = set()\n",
    "    while len(distinct_lect) < num_distinct_lect and len(res) > 0:\n",
    "        doc = res.pop(0)\n",
    "        if doc.metadata['lecture_number'] not in distinct_lect_ids:\n",
    "            distinct_lect.append(\n",
    "                {\n",
    "                    \"lecture_number\": doc.metadata['lecture_number'],\n",
    "                    \"lecture_title\": doc.metadata['lecture_title'],\n",
    "                    \"lecture\": doc.page_content,\n",
    "                }\n",
    "            )\n",
    "            distinct_lect_ids.add(doc.metadata['lecture_number'])\n",
    "    return distinct_lect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from app.chains.prompts import QA_CHAIN_PROMPT_TEMPLATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "gpt4o = ChatOpenAI(\n",
    "    model='gpt-4o-2024-08-06',\n",
    "    temperature=0.0,\n",
    "    openai_api_key=openai_key,\n",
    "    cache=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "def qa(\n",
    "    question: str,\n",
    "    question_type: int,\n",
    "    options: List[str],\n",
    "    num_distinct_lect: int = 3,\n",
    "):\n",
    "    relevant_lectures = get_relevant_lecture_slide(\n",
    "        query=question,\n",
    "        num_distinct_lect=num_distinct_lect\n",
    "    )\n",
    "\n",
    "    prompt = QA_CHAIN_PROMPT_TEMPLATE.format(\n",
    "        lecture_notes=json.dumps(relevant_lectures, indent=4),\n",
    "        question=question,\n",
    "        question_type=question_type,\n",
    "        answer_options=json.dumps(options, indent=4),\n",
    "    )\n",
    "\n",
    "    resp = gpt4o.invoke(prompt)\n",
    "    resp = json.loads(resp.content)\n",
    "    return resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"cited_lecture_notes\": [\n",
      "        \"07, Frames\"\n",
      "    ],\n",
      "    \"answers\": [\n",
      "        \"1, A frame is a data structure used to represent a stereotypical situation.\"\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "query = \"What is a frame in AI?\"\n",
    "question_type = 1\n",
    "options = [\n",
    "    \"1. A frame is a data structure used to represent a stereotypical situation.\",\n",
    "    \"2. A frame is something you use to hang a picture.\",\n",
    "    \"3. A frame is a type of computer monitor.\",\n",
    "]\n",
    "resp = qa(\n",
    "    question=query,\n",
    "    question_type=question_type,\n",
    "    options=options,\n",
    ")\n",
    "print(json.dumps(resp, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "exam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
